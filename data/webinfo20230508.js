module.exports = {
	title: "text Factory",
	subtitle: "research on algorithmic text",
	abstract: "thoughts and experiments in handmade code / generative text",
	indexname: "index.html",
	root: "textfactory",
	url: "https://textfactory.work/index.html",
	hasDashboard: false,
	hasAnimation: false,
	cssurl: "/css/core.css",
	codeurl: "/code/core.js",
	bodybg: ["warmgray","warmblack","red"],
	mainbg: ["warmgray","warmblack","black"],
	pictureurl: "https://mctavish.work//apple-touch-icon.png",
	text: `<article>
	<header>
	<h1>intelligence</h1>
	</header>
	<p>
	knot intelligence hand intelligence weave intelligence organic intelligence photosynthetic intelligence tactile intelligence heart intelligence walking intelligence luminous half-closed eye subliminal intelligence
	local knowledge fleeting moment thoughts
	</p>
	</article>
	<article>
	<header>
	<h1>problematic physics</h1>
	</header>
	<blockquote>
	<p>to know to no to immerse in the ecstatic electric torrent</p>
	<p>to become fodder chalk outline vacant stalk</p>
	</blockquote>
	<p>
	opaque, innumerable, unknowable model parameters
	</p>
	<p>unexamined model dimensions not explicit not transparent not articulated expressed considered</p>
	<p>goals not confessed unexamined intentions implicit profit motives capitalist frameworks</p>
	<p>circular reasoning ::: model; training evaluation text spew becomes text input becomes confirmation</p>
	<p>vast (yet skewed) data input becomes hyperspecific, averaged output</p>
	<p>
	averaging ::: we can all sound like the mean expression of slanted datasets
	</p>
	<p>these are hyper efficient colonization machines</p>
	<p>a confirmation bias dream machine ::: it is an endless, escher-like mirror of the uber-kings of data ::: show me what a tech worker looks like ... check! looks right to me! (says the echo chamber)</p>
	<p>
		resources / effort / emphasis should be expended in creating self-documenting neural leaps / compression / distillation ... filters / assumptions / the shape of data that honed parameters ::: but this has no market value & there is very little regulating the application of these highly inaccurate, unpredictable tools on real-life problems that impact real people in real time
	</p>
	</article>
	<article>
	<header><h1>the environmental costs of LLMs</h1></header>
	<p>the resources used in chatgpt requests (let alone their original large-language model type training source) are astronomical .... we will definitely kill the earth by blithely engaging in frequent "chats." Although, search engines will increasingly use AI technology thereby making us all complicit in an exponential increase in energy costs for even our simple, curious search requests.</p>
	<p>we are in a LLM (Large Language Model) arms race between a small number of capitalist tech giants ::: sustainability of the planet isn't at the top of their list of priorities</p>
	<p>
		tech is often seen being as "resource-less" "objective" "cloud-like" "all-knowing" "pure" "outside the market" just thought science progress not dirty oil-burning, skewed, colonialist, ... this is the manhattan project ... a bunch of brilliant minds (white, priviledged men) working to push forward human understandiing of the world
	</p>
	<p>large language models are stochastic parrots, supercharged autocorrect .... hyper-powerful averaging machines</p>
	</article
	<article>
	<header><h1>role of an artist</h1><h2>dada the data</h2></header>
	<p>fodder ::: unpaid providers of honing advice, text, images, private data</p>
	<p>greenwash ::: make it seem cute ::: a toy</p>
	<p>
::: resist ::: flood the system ::: queer-up / dada the data
uber ze honey hive ::: electric phosynthetic queen ::: networked revolutionaries artists of the world :::
pollinate :::
</p>
<p>refuse ::: punk it up ::: create "bad text" "hand-hewn artifacts ... zines ... offline</p>
<p>do we need models trained on hundreds of billions of data points to create a poem about birds?</p>
<p>the tools we choose influence the work we make ::: cello, printing press, brush, pen, ...</p>
<p>we get to choose our tools ::: our hands ::: our bodies ::: our minds get to be a part of our creative process</p>
	</article>
	<article>
	<header><h1>references</h1><h2>more soon ...</h2></header>
	<p><a href="https://nmdprojects.net/teleconferences/nmd_webinar_ai_in_classroom_2023.html">AI in the classroom</a></p>
	<p><a href="https://www.theatlantic.com/technology/archive/2023/05/generative-ai-social-media-integration-dangers-disinformation-addiction/673940/">THe Atlantic: AI and toxic social media potential</a></p>
	<p><a href="https://umaine.edu/learnwithai/">University of Maine conversations about AI</a></p>
	<blockquote>
	<p>"Rather, it is built to maximize the extraction of wealth and profit – from both humans and the natural world – a reality that has brought us to what we might think of it as capitalism’s techno-necro stage."</p>
	<p><a href="https://www.theguardian.com/commentisfree/2023/may/08/ai-machines-hallucinating-naomi-klein">Klein, N. (2023, May 8). AI machines aren’t ‘hallucinating’. But their makers are.</a></p>
	</blockquote>
	<p><a href="https://www.numenta.com/blog/2022/05/24/ai-is-harming-our-planet/">energy use: a description of how it works</a></p>
	<blockquote>
	<p>"We need to take a step back and acknowledge that simply building ever-larger neural networks is not the right path to generalized intelligence. From first principles, we need to push ourselves to discover more elegant, efficient ways to model intelligence in machines. Our ongoing battle with climate change, and thus the future of our planet, depend on it."</p>
	<p><a href="https://www.forbes.com/sites/robtoews/2020/06/17/deep-learnings-climate-change-problem/?sh=5556d9a66b43">energy use link</a></p>
	</blockquote>
	<p><a href="https://www.govtech.com/question-of-the-day/how-much-water-does-chatgpt-drink-for-every-20-questions-it-answers">How much water does ChatGPT ‘drink’ for every 20 questions it answers?</a></p>
	<blockquote>
	<p>"he high cost of training and “inference” — actually running — large language models is a structural cost that differs from previous computing booms. Even when the software is built, or trained, it still requires a huge amount of computing power to run large language models because they do billions of calculations every time they return a response to a prompt. By comparison, serving web apps or pages requires much less calculation."</p>
	<p><a href="https://www.cnbc.com/2023/03/13/chatgpt-and-generative-ai-are-booming-but-at-a-very-expensive-price.html">cnbc: the cost of ai</a></p>
	</blockquote>
	<blockquote>
	<p>"To take just one example that’s very much in the news, ChatGPT-3—which we wrote about recently—has 175 billion machine learning (ML) parameters. It was trained on high-powered NVIDIA V100 graphical processing units (GPU), but researchers say it would have required 1,024 GPUs, 34 days and $4.6 million if done on A100 GPUs.
</p><p>
And while energy consumption was not officially disclosed, it is estimated that ChatGPT-3 consumed 936 MWh. That’s enough energy to power approximately 30,632 US households for one day, or 97,396 European households for the same period."
</p>
<p><a href="https://digitally.cognizant.com/ais-energy-use-isnt-sustainable-enter-tinyml-wf1584550">Cognizant blog</a></p>
	</blockquote>
	</article>`,
}
/*
knot intelligence hand intelligence

- problem with the physics of LLM 
	- opaque parameters / dimensions / variables
	- circular train / evaluation ::: limited dataset / limited feedback providers / limited evaluation data
	- escher mirror ... show me what a tech worker looks like ... check! looks right to me!
	- complexity of model ::: not human-understandable, not "elegant"
		-putting resources / effort / emphasis on self-documenting nural leaps / compression / distillation ... filters / assumptions / the shape of data that honed parameters has no market value
		- tech is always seen as "resource-less" "objective" "cloud-like" "all-knowing" "pure" "outside the market" just thought science progress not dirty oil-burning, skewed, colonialist, ... this is the manhattan project ... a bunch of brilliant minds (white, priviledged men) working to push forward human understandiing of the world
		- like a "classics" education ... "The Classics" 
	- a world / landscape of text ::: worldly, tactile, cross-sensory experience filtered through text is the basis for LLM
	- averaging ::: we can all sound like the mean expression of slanted datasets
- problem with the environmental cost of LLM AI
- problem with the data of AI
- problem with the tool of AI in art production / human communication

## Notes on touch ##

Glass touch ::: tap tap tap ::: reduction of communication to body-less, linear, word tapping ::: message transmission

Need for language to talk about AI models in the commons
See the rapid innovation and language emergence in the ProTactile community
Interest in the expanded meaning of a touch-centered communication mode

the role of the artist ::: resist flood refuse queer-up dada
uber ze honey hive ::: electric phosynthetic queen ::: networked revolutionaries artists of the world :::
pollinate

*/
